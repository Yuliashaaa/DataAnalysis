{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 4: Advanced Neural Nets\n",
    "### Шевченко Юлія, ФІ-31мн"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40fa658d2cd0050c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lab Task:\n",
    "\n",
    "1. _**Завдання щодо генерації текстів або машинного перекладу (на вибір) на базі рекурентних мереж або трансформерів (на вибір)**_. Вирішити завдання щодо генерації текстів або машинного перекладу. Особливо вітаються україномовні моделі.  \n",
    "2. Провести експерименти з моделями бібліотеки HF Transformers за допомогою (наприклад) Pipeline модуля.\n",
    "3. _**Завдання щодо генерації або стилізації зображень (на вибір)**_. Вирішити завдання перенесення стилю або генерації зображень (архітектура за вашим вибором: GAN/DCGAN/VAE)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "420894ed7bfa11d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Study\\Sem_9\\DA\\DataAnalysis\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "# All the imports for the task\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.src.preprocessing.image import ImageDataGenerator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T22:00:13.703246400Z",
     "start_time": "2024-01-11T22:00:08.990530900Z"
    }
   },
   "id": "f97c6fadc206fbce",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a60c0d6eb7305a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
